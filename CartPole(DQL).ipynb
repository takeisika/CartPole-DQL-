{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Install the Corresponding Version"
      ],
      "metadata": {
        "id": "EqfnJHa02xcD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gTtxhXVRufuG",
        "outputId": "d5213f3c-511e-4649-b73a-f693e06e7943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.10.0\n",
            "  Downloading tensorflow-2.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.0/578.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.8.0)\n",
            "Collecting keras<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.10.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.10.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.16.0)\n",
            "Collecting tensorboard<2.11,>=2.10 (from tensorflow==2.10.0)\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (0.32.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0 (from tensorflow==2.10.0)\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.10.0) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.11,>=2.10->tensorflow==2.10.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, keras, tensorflow-estimator, tensorboard-data-server, protobuf, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.10.0 keras-preprocessing-1.1.2 protobuf-3.19.6 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.10.0)\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.8.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (23.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.10.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (0.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ],
      "source": [
        "#対応するversionをinstall\n",
        "#TensorFlow バージョン 2.10 が動くのは、Python 3.9 (Jupiter Notebook運営設定) or Python 3.10 (Google Colaboratory運営設定)\n",
        "#kerasとkeras rlは自動的に、tensorflowとmatch\n",
        "!pip install tensorflow==2.10.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip installして、runtimeを終了した後、ちゃんとintended versionは入っているかをcheck\n",
        "!pip show keras\n",
        "!pip show keras-rl2\n",
        "!pip show tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99e68a3Uvyel",
        "outputId": "28342d29-3757-48c8-b8ea-d91b6641b6e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: keras\n",
            "Version: 2.10.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: tensorflow\n",
            "Name: keras-rl2\n",
            "Version: 1.0.5\n",
            "Summary: Deep Reinforcement Learning for Tensorflow 2 Keras\n",
            "Home-page: https://github.com/wau/keras-rl2\n",
            "Author: Taylor McNally\n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: tensorflow\n",
            "Required-by: \n",
            "Name: tensorflow\n",
            "Version: 2.10.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
            "Required-by: dopamine-rl, keras-rl2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAIGym Basic Info"
      ],
      "metadata": {
        "id": "AQCH1I8C27Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the easiest gym\n",
        "\n",
        "import gym\n",
        "\n",
        "#基本情報: env.reset()で環境がリセットされ、初期状態になる。その後env.step(action)で行動し、env.render()で描画します。\n",
        "\n",
        "\n",
        "env = gym.make('CartPole-v0', render_mode='human')\n",
        "#envとは、The basketball court, all the players, the ball, the hoop, the rules of the game, etc.\n",
        "env.reset()\n",
        "#env.reset() is necessary to ensure that the agent always starts from a consistent, defined starting state in each episode.\n",
        "#starting a new game. The score is set back to 0-0, the clock is reset, the players are put back in their starting positions, and so on.\n",
        "\n",
        "\n",
        "print(env.observation_space)\n",
        "#結果: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
        "#The two arrays [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38] and [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]: represent the minimum and maximum possible values, respectively, for each of the four dimensions of the observation.\n",
        "#(4,): the shape of the observation space, meaning each observation is a 4-dimensional vector.\n",
        "#Cart Position: The cart's position along the x-axis. (The range of values is typically within (-2.4, 2.4).)\n",
        "#Cart (速さ): The cart's velocity along the x-axis. (The range of values is typically within (-Inf, Inf).)\n",
        "#Pole Angle: The pole's angle from the vertical. (The range of values is typically within (-41.8, 41.8) degrees.)\n",
        "#Pole Velocity (速さ) At Tip: The velocity of the tip of the pole. (The range of values is typically within (-Inf, Inf).)\n",
        "\n",
        "\n",
        "for _ in range(50):\n",
        "    env.render()  #動きをvisualize\n",
        "    action = env.action_space.sample()\n",
        "    #action_spaceは、the things you can do in the game. In basketball, dribbling, passing, shooting, blocking, etc.\n",
        "    #今回のOpen AI gymにおけるaction_spaceは右に進むか左に進むかなので、2通りしかactionない\n",
        "    #sample()はget a random action\n",
        "\n",
        "    observation, reward, done, info = env.step(action)\n",
        "\n",
        "\n",
        "    print(observation, reward, done, info)\n",
        "    #[-0.02958055 -0.7443554   0.045422    1.1290977 ] 1.0 False, {}という情報がrange分並ぶ\n",
        "    #rewardは1と今回全部決まってる: In the CartPole-v0 environment, the reward is indeed always 1 for every time step the agent is able to keep the pole upright.\n",
        "    #infoはenvにおけるaddiitional infoを指すけど、ほぼempty値だからignoreで良い\n",
        "    #print(observation)だと1個1個のactual値が確認出来る、対してprint(observation space)だと全体のまとめ値(max-min, etc)が確認出来る\n",
        "\n",
        "    if done == True: #done == Trueはepisode終わったらの意味\n",
        "        env.reset() #episode毎に、初期化 #starting a new game. The score is set back to 0-0, the clock is reset, the players are put back in their starting positions, and so on.\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D2uui_twOQU",
        "outputId": "c92475d3-af31-47e4-c716-1fab7f8bd7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "[-0.04904597  0.17610407  0.01626318 -0.2989193 ] 1.0 False {}\n",
            "[-0.04552389  0.37099046  0.0102848  -0.58642906] 1.0 False {}\n",
            "[-0.03810408  0.17572598 -0.00144378 -0.29052415] 1.0 False {}\n",
            "[-0.03458956 -0.01937535 -0.00725427  0.00170307] 1.0 False {}\n",
            "[-0.03497707  0.17584988 -0.0072202  -0.2932598 ] 1.0 False {}\n",
            "[-0.03146007  0.37107402 -0.0130854  -0.5882111 ] 1.0 False {}\n",
            "[-0.02403859  0.56637675 -0.02484962 -0.8849871 ] 1.0 False {}\n",
            "[-0.01271106  0.37160087 -0.04254936 -0.60021853] 1.0 False {}\n",
            "[-0.00527904  0.17709918 -0.05455374 -0.3212358 ] 1.0 False {}\n",
            "[-0.00173705  0.37295386 -0.06097845 -0.6306116 ] 1.0 False {}\n",
            "[ 0.00572202  0.17873341 -0.07359068 -0.35773894] 1.0 False {}\n",
            "[ 0.00929669 -0.01526939 -0.08074547 -0.08913851] 1.0 False {}\n",
            "[ 0.0089913   0.18091153 -0.08252823 -0.4061645 ] 1.0 False {}\n",
            "[ 0.01260953  0.37710086 -0.09065152 -0.72368264] 1.0 False {}\n",
            "[ 0.02015155  0.57335186 -0.10512517 -1.0434655 ] 1.0 False {}\n",
            "[ 0.03161859  0.37977096 -0.12599449 -0.7855471 ] 1.0 False {}\n",
            "[ 0.03921401  0.576378   -0.14170542 -1.1150644 ] 1.0 False {}\n",
            "[ 0.05074157  0.38337156 -0.16400671 -0.8699787 ] 1.0 False {}\n",
            "[ 0.058409    0.58029896 -0.18140629 -1.209408  ] 1.0 False {}\n",
            "[ 0.07001498  0.7772394  -0.20559445 -1.5530127 ] 1.0 False {}\n",
            "[ 0.08555976  0.58508915 -0.2366547  -1.3308773 ] 1.0 True {'TimeLimit.truncated': False}\n",
            "[-0.01762723 -0.1686509  -0.02105905  0.24963945] 1.0 False {}\n",
            "[-0.02100025  0.02676537 -0.01606626 -0.04961084] 1.0 False {}\n",
            "[-0.02046494  0.22211397 -0.01705847 -0.3473192 ] 1.0 False {}\n",
            "[-0.01602266  0.02723875 -0.02400486 -0.06006385] 1.0 False {}\n",
            "[-0.01547789 -0.16753094 -0.02520614  0.22494976] 1.0 False {}\n",
            "[-0.01882851 -0.36228374 -0.02070714  0.5095764 ] 1.0 False {}\n",
            "[-0.02607418 -0.16687629 -0.01051561  0.21044055] 1.0 False {}\n",
            "[-0.02941171 -0.3618463  -0.0063068   0.4997879 ] 1.0 False {}\n",
            "[-0.03664863 -0.5568788   0.00368896  0.79047656] 1.0 False {}\n",
            "[-0.04778621 -0.36180767  0.01949849  0.49895647] 1.0 False {}\n",
            "[-0.05502236 -0.55719906  0.02947762  0.79771996] 1.0 False {}\n",
            "[-0.06616634 -0.7527128   0.04543202  1.0995283 ] 1.0 False {}\n",
            "[-0.0812206  -0.5582173   0.06742258  0.82143855] 1.0 False {}\n",
            "[-0.09238494 -0.7541938   0.08385135  1.1345427 ] 1.0 False {}\n",
            "[-0.10746882 -0.95030683  0.10654221  1.4523021 ] 1.0 False {}\n",
            "[-0.12647496 -0.75664276  0.13558824  1.1947173 ] 1.0 False {}\n",
            "[-0.1416078  -0.56351155  0.1594826   0.9474203 ] 1.0 False {}\n",
            "[-0.15287805 -0.7603798   0.178431    1.2856644 ] 1.0 False {}\n",
            "[-0.16808563 -0.9572667   0.20414428  1.6284868 ] 1.0 False {}\n",
            "[-0.18723097 -1.1541191   0.23671402  1.9772364 ] 1.0 True {'TimeLimit.truncated': False}\n",
            "[-0.02315812 -0.18109922  0.02335298  0.2754325 ] 1.0 False {}\n",
            "[-0.0267801   0.01368189  0.02886163 -0.00979436] 1.0 False {}\n",
            "[-0.02650646 -0.18184184  0.02866574  0.29185322] 1.0 False {}\n",
            "[-0.0301433  -0.37736052  0.03450281  0.5934374 ] 1.0 False {}\n",
            "[-0.03769051 -0.18273811  0.04637156  0.3118193 ] 1.0 False {}\n",
            "[-0.04134527  0.01169359  0.05260794  0.03411359] 1.0 False {}\n",
            "[-0.0411114  -0.18414176  0.05329021  0.34291983] 1.0 False {}\n",
            "[-0.04479424 -0.37997976  0.06014861  0.6519197 ] 1.0 False {}\n",
            "[-0.05239383 -0.18574478  0.073187    0.37876716] 1.0 False {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAIGym Basic Practice"
      ],
      "metadata": {
        "id": "wd_5Rp993AHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "\n",
        "env = gym.make('CartPole-v0')\n",
        "#envとは、バスケコート, プレイヤー、ボール、ルール, etc.\n",
        "\n",
        "states = env.observation_space.shape[0]\n",
        "print(states)\n",
        "actions = env.action_space.n\n",
        "\n",
        "\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "#generates a sequence of numbers starting from 1 and ending at episodes+1 (exclusive of episodes+1)\n",
        "#つまり、今回は[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]をoutputする\n",
        "\n",
        "    state = env.reset()\n",
        "    #0-0からgame restart\n",
        "    #ちなみにenv.reset()したとしても毎回x-axis 0から始めるよというわけではない。どこから開始するかは毎回randomにてselectされる(overfit防ぐ為)\n",
        "\n",
        "    done = False\n",
        "    score = 0\n",
        "    #envが持つ値はobservation, reward, done, infoだから、doneとscoreだけ別々に初期状態に設定してあげる必要性\n",
        "\n",
        "    while not done:\n",
        "        #not doneの間(done Trueになるまで)、each episodeはtrainingの場数を踏む\n",
        "        #doneは、the agent fails to balance the pole, i.e., when the pole tips over too much or the cart moves off the displayの時に起こる\n",
        "        #--->だからeach episodeがhow many 場数trainingしたかはvary\n",
        "\n",
        "\n",
        "\n",
        "        #visualize\n",
        "        #img = plt.imshow(env.render(mode='rgb_array'))\n",
        "        #display.display(plt.gcf())\n",
        "        #display.clear_output(wait=True)\n",
        "\n",
        "\n",
        "\n",
        "        action = random.choice([0,1])\n",
        "        #actionは今回右か左かの2通りしかない #0~1の値ではなく、0か1か(右か左か)\n",
        "        #When action is 0, a force of -1.0 is applied to the cart causing it to move to the left\n",
        "        #when action is 1, a force of +1.0 is applied to the cart causing it to move to the right.\n",
        "        #だけど、どれくらい実際にx-axisに沿って動くかは、その時におけるstickの角度やpositionに左右されるから、必ずしもx-axisにおける-1 or +1かの変化ではない\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "        #print('After action {}, new state: {}, score{}、done{}'.format(action, n_state, score, done)) #⭐️action毎⭐️ #whileの中の場数毎まで細かく確認したければ、こっち\n",
        "    #print('Episode:{} Score:{} State:{}'.format(episode, score, state)) #⭐️episode毎⭐️ #while後のepisode毎のまとめ最終結果だけ確認したければ、こっち\n",
        "\n",
        "\n",
        "###まず、state = env.reset()とdone = Falseとscore = 0を設定してからepisode開始(全部10個)###\n",
        "###not done(done False)の間、つまり、poleが倒れてdone Trueになるまで、whileの中の処理が反復される。\n",
        "###-----> actionは右か左かの2通りで、それぞれ具体的にどれくらいx-axisの右左にいくかは、poleの角度etc物理原則に左右されるから必ずしもx-axisにおける+-1(右左)の動きではない\n",
        "###毎回actionした結果が、print('After action {}, new state: {}, score{}、done{}'.format(action, n_state, score, done)) にてget\n",
        "###done Trueになるまでactionしたepisode毎のまとめの結果が、print('Episode:{} Score:{} State:{}'.format(episode, score, state)) にてget\n",
        "\n",
        "###rewardはopen AI gymではalways 1だけど他は違うことある\n",
        "###state = env.reset()は必ずしも毎回x-axis 0地点に行くわけではない。overfittingを防ぐ為に、start地点はrandomに選ばれる"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jU7IUlTwSpq",
        "outputId": "aafd3aa8-2674-43be-8e95-1c04152342f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Deep Reinforcement Learning 本題**"
      ],
      "metadata": {
        "id": "IawTJmLN3GDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Deep Learning Model with Keras"
      ],
      "metadata": {
        "id": "C_hfD7XX3JK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###まず、inputとしてstateをぶち込み、outputとしてそれぞれのactionに対応するQvalueをoutputするNNを構築する###\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "#neural networkのlayerをbuildする時に必要\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "\n",
        "#agentを次のcellにてbuildする時に必要\n",
        "#(こっちのcellに加えた理由は、model = build_model(states, actions)というようにmodelを定義した後に、以下をimportしようとすると、Functional' object has no attribute errorが起きる)\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "states = env.observation_space.shape[0] #4\n",
        "#env.observation_spaceは\n",
        "#Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
        "#みたいな値を持つからenv.observation_space.shapeは(4,)\n",
        "#だからshape[0]は4\n",
        "actions = env.action_space.n #2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "###⭐️Deep RLでは、stateだけをinputとしてぶち込んだら、それぞれのactionに対応するQvalueがoutputされる⭐️###\n",
        "def build_model(states, actions):\n",
        "    model = tf.keras.Model()\n",
        "\n",
        "    # Input layer\n",
        "    inputs = tf.keras.Input(shape=(1, states)) #後で、state dataいっぱいぶち込むから、予めdata入るようにshapeをstate dataに合わせておく\n",
        "\n",
        "    # Flatten layer\n",
        "    x = Flatten()(inputs) #denseが待っているから、1次元にする\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(24, activation='relu')(x)\n",
        "    x = Dense(24, activation='relu')(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(actions, activation='linear')(x) #actionsは2 #右か左かの合計2通りのそれぞれactionに対応するQvalueがoutputされる\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model(states, actions)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WJEpRmhwWbE",
        "outputId": "f2934869-617f-4379-e495-c8d74aa7df1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1, 4)]            0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 24)                120       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 24)                600       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 770\n",
            "Trainable params: 770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Agent With Keras-RL"
      ],
      "metadata": {
        "id": "mhd8Ag153RvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![download.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "rURCpa4A3TO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Build Agent###\n",
        "\n",
        "policy = BoltzmannQPolicy() #BoltzmannQPolicyにてtraining進行します\n",
        "\n",
        "###BoltzmannQPolicyとは###\n",
        "#例えば、先生がある問題に正しく回答してくれる生徒をpickしたい\n",
        "#学期初めだと、まだ生徒の事知らないから(temperature high)、選ぶ生徒のrandom性高い\n",
        "#学期進むにつれて、テストなどによって、先生は生徒の事を知り始める(temperature drop)、より成績が悪い生徒(low energies)より成績が良い生徒(high energies)を選ぶ\n",
        "#学期終わりには、先生は生徒の事を知り尽くしている(temperature low)から、almost always成績が良い人が選ばれる可能性が高い(random性低い)\n",
        "#上記の例では、先生のchoiceが学期(temperature)と成績(energies)の高低に基づく(temperature低いとrandom)\n",
        "#RLのcontextでは、Q-valueが成績にあたり、typically最初は全部Q-valueないからrandom性高いけど、段々action毎のQ-valueが分かってくる(temperature drops)\n",
        "#そしたらRL agentはhigher Q-valueのactionのtrainingによりfocusするようになる(higher valueの方が、rewardに直接影響するから重要だと考える)\n",
        "\n",
        "memory = SequentialMemory(limit=50000, window_length=1)\n",
        "#1 of 50000 memoryは単純に、各action毎のexperience (like以下)\n",
        "#{\"state\": [0, 1, 0, 0, 0, 0, 0, 0, 0],\"action\": 1,\"reward\": 1,\"next_state\":[1, 0, 0, 0, 0, 0, 0, 0, 0],\"done\": False}\n",
        "#window_lengthは何個のこういうactionをひとつのexperienceとして記憶するかを定義。今回はwindow_lengthは1だから、毎回毎回のaction毎にひとつのexperienceをとして記憶\n",
        "#board gameなどにて複数のactionでひとつの意味的stepになる時に、width_length複数という必要性が出てくる\n",
        "\n",
        "dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "#model, memory, policy, nb_actions, etcはDQNAgent model(Keras RL default)のattributes\n",
        "#nb_steps_warmup: The number of steps that the agent will take before it starts learning->These initial steps allow the agent to gather some experiences to start learning from.\n",
        "#target_model_updateに関して:\n",
        "#DQNのneural networkには、online modelとtarget modelがある\n",
        "#online modelは頑張ってbike乗れるように成功/失敗体験を毎回update、一方、target modelはonline modelの見本的存在\n",
        "#(ただ闇雲に成功/失敗を毎回updateするだけでなく、target modelの見本例を観察して活かす)\n",
        "#target modelのupdateをゆっくりにすることにより、見本例がfrequently変化しないから、安定して学習出来る (目標コロコロ変わったら、学習効率悪い)\n",
        "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])\n",
        "#metricsは測定方法。MAE（Mean Absolute Error/平均絶対値誤差）は、真の値と予測値の差の絶対値の平均です。"
      ],
      "metadata": {
        "id": "wfiK95aswb_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the Pre-trained Model"
      ],
      "metadata": {
        "id": "MM_yTUnd3dKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "scores = dqn.test(env, nb_episodes=20, visualize=True)\n",
        "print(np.mean(scores.history['episode_reward']))\n",
        "#train前は、rewardは勿論、stepに関してもconfidentに正しく失敗せずに進められてないから、値低い\n",
        "#reward: 10.000とか steps: 10とか"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMgDUJ2j13ys",
        "outputId": "e587453b-a168-48d5-b56d-9d5b7addc6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1: reward: 23.000, steps: 23\n",
            "Episode 2: reward: 9.000, steps: 9\n",
            "Episode 3: reward: 9.000, steps: 9\n",
            "Episode 4: reward: 10.000, steps: 10\n",
            "Episode 5: reward: 9.000, steps: 9\n",
            "Episode 6: reward: 9.000, steps: 9\n",
            "Episode 7: reward: 9.000, steps: 9\n",
            "Episode 8: reward: 10.000, steps: 10\n",
            "Episode 9: reward: 10.000, steps: 10\n",
            "Episode 10: reward: 8.000, steps: 8\n",
            "Episode 11: reward: 35.000, steps: 35\n",
            "Episode 12: reward: 9.000, steps: 9\n",
            "Episode 13: reward: 8.000, steps: 8\n",
            "Episode 14: reward: 10.000, steps: 10\n",
            "Episode 15: reward: 9.000, steps: 9\n",
            "Episode 16: reward: 10.000, steps: 10\n",
            "Episode 17: reward: 11.000, steps: 11\n",
            "Episode 18: reward: 9.000, steps: 9\n",
            "Episode 19: reward: 9.000, steps: 9\n",
            "Episode 20: reward: 8.000, steps: 8\n",
            "11.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ],
      "metadata": {
        "id": "69Z0cZyU3gXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.fit(env, nb_steps=50000, visualize=True, verbose=1) ###trainingします###\n",
        "#envはremove出来ない bc 上で定義したenv = gym.make('CartPole-v0')だから\n",
        "#verbose=1だとtraining process表示される、verbose=0だと非表示"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSn9sJbS1847",
        "outputId": "d368f3aa-5f34-4f43-ab34-864433372a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "10000/10000 [==============================] - 220s 22ms/step - reward: 1.0000\n",
            "52 episodes - episode_reward: 188.846 [56.000, 200.000] - loss: 4.696 - mae: 38.433 - mean_q: 76.856\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 213s 21ms/step - reward: 1.0000\n",
            "51 episodes - episode_reward: 198.353 [156.000, 200.000] - loss: 6.020 - mae: 37.736 - mean_q: 75.536\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 211s 21ms/step - reward: 1.0000\n",
            "50 episodes - episode_reward: 199.800 [190.000, 200.000] - loss: 10.378 - mae: 40.897 - mean_q: 81.822\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 211s 21ms/step - reward: 1.0000\n",
            "50 episodes - episode_reward: 200.000 [200.000, 200.000] - loss: 13.022 - mae: 42.759 - mean_q: 85.494\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 212s 21ms/step - reward: 1.0000\n",
            "done, took 1068.461 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b017061af20>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the Trained Model"
      ],
      "metadata": {
        "id": "xYVr0j5l3jz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "scores = dqn.test(env, nb_episodes=20, visualize=True)\n",
        "print(np.mean(scores.history['episode_reward']))\n",
        "#train後は、rewardは勿論、stepに関してもconfidentに正しく失敗せずに進められてるから、値上昇"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVWtYzWe2A1N",
        "outputId": "91933e5e-8de6-4f5f-e9bf-d847e063b342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 20 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Trained Model"
      ],
      "metadata": {
        "id": "WaAx0ihe3mRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###training後のmodelを保存して使える###\n",
        "dqn.save_weights('dqn_weights.h5f', overwrite=True)\n",
        "\n",
        "#試しに、上記にてtrainingしたこと全てdelete\n",
        "del model\n",
        "del dqn\n",
        "del env\n",
        "\n",
        "#素材骨組みをそっくりそのまま再構築 (trainingは終わってない状態)\n",
        "env = gym.make('CartPole-v0')\n",
        "actions = env.action_space.n\n",
        "states = env.observation_space.shape[0]\n",
        "model = build_model(states, actions)\n",
        "dqn = DQNAgent(model=model, memory=memory, policy=policy, nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "\n",
        "#ここにすでにsaveしたtraining\n",
        "dqn.load_weights('dqn_weights.h5f')\n",
        "dqn.test(env, nb_episodes=5, visualize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV47Xe5f2DXF",
        "outputId": "6113ba48-e6bf-4cd5-9368-4a846e26d788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 5 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b0169e8b610>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}